{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "silver-rendering",
   "metadata": {},
   "source": [
    "# Clean Current Labor Edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deadly-resident",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import pyodbc\n",
    "#from nltk import word_tokenize\n",
    "#from spellchecker import SpellChecker\n",
    "import re\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-penalty",
   "metadata": {},
   "source": [
    "### Temp Manual Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "responsible-teens",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sharp-given",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "sys.path.insert(0, home_dir)\n",
    "from util import db, nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "liberal-petite",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = db.open_conn(is_prod=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceramic-shaft",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labor = db.get_table_pd(f\"SELECT * FROM dbo.Case_Detail WHERE Update_Date > '2021-04-16' and Detail_Notes is NULL\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bibliographic-profit",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labor = new_labor.loc[new_labor.id > 100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "excited-placement",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labor.dropna(how='all', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "twenty-calcium",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "title_cols = ['item_description', 'product_family','oem_company', 'level']\n",
    "\n",
    "new_labor = nlp.str_impute_lower(new_labor, title_cols)\n",
    "\n",
    "# new_cols = db.get_columns(table_name = \"Case_Detail\",conn_tup = conn)\n",
    "\n",
    "new_labor['detail_notes'] = new_labor[title_cols].agg(\" \".join, axis=1)\n",
    "\n",
    "token_full = nlp.tokenize_col(new_labor.detail_notes)\n",
    "cleaned_matched_pos = nlp.normalize_tokens(token_full)\n",
    "new_labor.detail_notes = [\" \".join(row) for row in cleaned_matched_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "iraqi-journalist",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_labor.to_csv(\"services_new.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-phone",
   "metadata": {},
   "source": [
    "## Load Data from Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "foreign-stage",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "surgical-excerpt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get datetime for SELECT query\n",
    "yesterday = date.today() - timedelta(days = 1)\n",
    "yes_str = yesterday.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "educational-lyric",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open connection to production db\n",
    "conn = db.open_conn(is_prod=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "actual-acquisition",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labor = db.get_table_pd(f\"SELECT * FROM dbo.Case_Detail WHERE Update_Date > '{yes_str}'\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "coastal-laugh",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_cols = ['item_description', 'product_family','oem_company', 'level']\n",
    "\n",
    "new_labor = nlp.str_impute_lower(new_labor, title_cols)\n",
    "\n",
    "new_cols = db.get_columns(table_name = \"Case_Detail\",conn_tup = conn)\n",
    "\n",
    "new_labor.detail_notes = new_labor[title_cols].agg(\" \".join, axis=1)\n",
    "\n",
    "token_full = nlp.tokenize_col(new_labor.detail_notes)\n",
    "cleaned_matched_pos = nlp.normalize_tokens(token_full)\n",
    "new_labor.detail_notes = [\" \".join(row) for row in cleaned_matched_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dress-mining",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.cnxn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-paint",
   "metadata": {},
   "source": [
    " Update Case_Detail Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "communist-pearl",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(new_rows)):\n",
    "        #TODO: Full_Position_Title to Detail_Notes\n",
    "    conn.cursor.execute(f\"UPDATE {table} SET Full_Position_Title='{new_rows.full_position_title[i]}' WHERE ID = {new_rows.id[i]}\")\n",
    "    conn.cnxn.commit()\n",
    "conn.cnxn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-astronomy",
   "metadata": {},
   "source": [
    "## Generate Tech Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "prerequisite-familiar",
   "metadata": {},
   "outputs": [],
   "source": [
    "laboredge = str_impute_lower(laboredge)\n",
    "\n",
    "laboredge['full_position'] = laboredge.position_title.str.lower()+\" \"+laboredge.product_category.fillna('').str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dedicated-islam",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tokens = tokenize_col(laboredge.full_position)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-album",
   "metadata": {},
   "source": [
    "### Find misspelled words (occur > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "competitive-falls",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flat_toks = list(set([item for sublist in pos_tokens for item in sublist]))\n",
    "stripped_toks = remove_punctuation(flat_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "regional-jurisdiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "misspelled = find_misspelled(stripped_toks)\n",
    "\n",
    "misspelled = list(set(misspelled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-center",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tech_terms = word_occur_more(laboredge.full_position, misspelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "isolated-montana",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_list_csv('abbr_all.csv',tech_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "violent-messaging",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "abbrev_ex = []\n",
    "for ab in tech_terms:\n",
    "    pattern = re.compile(r'(^|\\W)'+ab+r'($|\\W)')\n",
    "    positions = laboredge.full_position[laboredge.full_position.str.contains(pattern)]\n",
    "    abbrev_ex.append(positions)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dependent-package",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'term':tech_terms, 'example':abbrev_ex}).to_csv('tech_examples.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-saturn",
   "metadata": {},
   "source": [
    "#### Add Abbrevs to Spellchecker Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "collectible-waters",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_corr = pd.read_excel('tech_examples.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "absolute-salad",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_corr['is_abbrev'] = terms_corr.term !=terms_corr.full_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "sixth-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "addition_words = list(terms_corr.term)\n",
    "with open('tech_terms_pkl.txt', 'wb') as fh:\n",
    "   pickle.dump(addition_words, fh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "cross-impression",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ab_dict = {}\n",
    "for i, row in terms_corr[terms_corr.is_abbrev].iterrows():\n",
    "    ab_dict[row.term] = row.term+\" \"+row.full_term\n",
    "\n",
    "r_num = {'i': '1',\n",
    "         'ii': '2',\n",
    "         'iii': '3',\n",
    "         'iv': '4'}\n",
    "ab_dict = dict(ab_dict, **r_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepared-failing",
   "metadata": {},
   "source": [
    "### Write Clean Position Titles and Tech Dictionary to pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "chronic-watershed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create abbreviations dictionary pickle file\n",
    "with open('pickles/abbrev_pkl.txt', 'wb') as fh:\n",
    "   pickle.dump(ab_dict, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "great-local",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_pos_tokens = normalize_tokens(pos_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "desperate-preservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cleaned positions tokenized\n",
    "with open('pickles/positions_pkl.txt', 'wb') as fh:\n",
    "   pickle.dump(sub_pos_tokens, fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rolled-amplifier",
   "metadata": {},
   "source": [
    "#### Read from Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stainless-postage",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_pos_tokens = pd.read_pickle(r'pickles/positions_pkl.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "mobile-nutrition",
   "metadata": {},
   "outputs": [],
   "source": [
    "join_positions = [\" \".join(row) for row in clean_pos_tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-schedule",
   "metadata": {},
   "source": [
    "### Confirm Clean positions in same order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "answering-claim",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "enhanced-integer",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_matches = []\n",
    "for orig, clean in zip(laboredge.full_position, join_positions):\n",
    "    if fuzz.token_sort_ratio(orig, clean) <70:\n",
    "        low_matches.append([orig, clean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sixth-trial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1098"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(low_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-reality",
   "metadata": {},
   "source": [
    "### Create new Laboredge with clean Positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "psychological-mobile",
   "metadata": {},
   "outputs": [],
   "source": [
    "laboredge.full_position = join_positions\n",
    "laboredge.drop(columns=['idxdontneed'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "annual-recycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "laboredge.to_csv('labor_clean_pos.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "254.006px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
